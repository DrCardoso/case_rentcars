{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOikw+NI6bqz5RiyNilux84"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"X-jiorJ3NMiB"},"outputs":[],"source":["### Função para calcular a métrica pedida pela competição\n","def instacart_f1_score(data, user_id_col, true_col, pred_col):\n","    f1_scores = []\n","\n","    users = data[user_id_col].unique()\n","    for user in users:\n","        user_data = data[data[user_id_col] == user]\n","\n","        # Garantir que true_col e pred_col sejam conjuntos\n","        if isinstance(user_data[true_col].values[0], (np.integer, int)):\n","            y_true = {user_data[true_col].values[0]}\n","        else:\n","            y_true = set(user_data[true_col].values[0])\n","\n","        if isinstance(user_data[pred_col].values[0], (np.integer, int)):\n","            y_pred = {user_data[pred_col].values[0]}\n","        else:\n","            y_pred = set(user_data[pred_col].values[0])\n","\n","        if len(y_true) == 0 and len(y_pred) == 0:\n","            f1_scores.append(1.0)\n","        elif len(y_true) == 0 or len(y_pred) == 0:\n","            f1_scores.append(0.0)\n","        else:\n","            tp = len(y_true & y_pred)\n","            fp = len(y_pred - y_true)\n","            fn = len(y_true - y_pred)\n","\n","            precision = tp / (tp + fp) if tp + fp > 0 else 0\n","            recall = tp / (tp + fn) if tp + fn > 0 else 0\n","            f1 = 2 * precision * recall / (precision + recall) if precision + recall > 0 else 0\n","            f1_scores.append(f1)\n","\n","    return np.mean(f1_scores)\n","\n","# Função de Avaliação\n","def get_ks(y, y_pred):\n","    return ks_2samp(y_pred[y == 1], y_pred[y != 1]).statistic\n","\n","# Função de Avaliação\n","def metricas_validacao(model, data, target_):\n","    data = data.copy()\n","    prob = model.predict_proba(data.drop(columns=[target_]))[:, 1]\n","\n","    auc = metrics.roc_auc_score(data[target_], prob)\n","    ks = get_ks(data[target_], prob)\n","    logloss = metrics.log_loss(data[target_], prob)\n","    accuracy = metrics.accuracy_score(data[target_], (prob > 0.5).astype(int))\n","    precision = metrics.precision_score(data[target_], (prob > 0.5).astype(int))\n","    recall = metrics.recall_score(data[target_], (prob > 0.5).astype(int))\n","    f1 = metrics.f1_score(data[target_], (prob > 0.5).astype(int))\n","\n","    print(f'AUC: {auc:.4f}, KS: {ks:.4f}, Log Loss: {logloss:.4f}, Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}')\n","    return auc, ks, logloss, accuracy, precision, recall, f1\n","\n","# Função de Plotagem\n","def save_plot(plot_func, filename, path='.', format='pdf'):\n","    # Criar uma nova figura para evitar conflitos\n","    plt.figure()\n","    # Gerar e salvar o gráfico\n","    plot_func()\n","    full_path = os.path.join(path, f\"{filename}.{format}\")\n","    plt.savefig(full_path, format=format)\n","    # Fechar a figura para liberar memória\n","    plt.close()\n","    print(f\"Gráfico salvo como {full_path}\")\n","\n","# Função de Conversão\n","def convert_data_types():\n","    np.int = np.int32\n","    np.float = np.float64\n","    np.bool = np.bool_\n","\n","# Função de modelagem\n","class SimplifiedLGBMModel:\n","    def __init__(self, data, features, target, categorical_features=[], test_flag_label=None, col_safra=None, test_size=0.3, random_state=42):\n","        self.data = data\n","        self.features = features\n","        self.target = target\n","        self.categorical_features = categorical_features\n","        self.test_flag_label = test_flag_label\n","        self.col_safra = col_safra\n","        self.test_size = test_size\n","        self.random_state = random_state\n","        self.model = None\n","        self.params = {\n","            'force_col_wise': True,\n","            'min_child_samples': 20,\n","            'max_depth': 10,\n","            'min_split_gain': 0.01,\n","            'num_leaves': 100,\n","            'n_estimators': 100\n","        }\n","        self.X_train, self.X_test, self.y_train, self.y_test = self.preprocess()\n","\n","    def preprocess(self):\n","        if self.test_flag_label:\n","            train_data = self.data[self.data[self.test_flag_label] == 0]\n","            test_data = self.data[self.data[self.test_flag_label] == 1]\n","            X_train, y_train = train_data[self.features], train_data[self.target]\n","            X_test, y_test = test_data[self.features], test_data[self.target]\n","        else:\n","            X = self.data[self.features]\n","            y = self.data[self.target]\n","            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=self.test_size, random_state=self.random_state, stratify=y)\n","        return X_train, X_test, y_train, y_test\n","\n","    def find_irrelevant_features(self):\n","        const_features = [col for col in self.features if self.data[col].nunique() == 1]\n","        self.features = [col for col in self.features if col not in const_features]\n","        self.update_datasets()\n","        print(f\"Removed constant features: {const_features}\")\n","\n","    def find_correlated_features(self):\n","        corr_matrix = self.data[self.features].corr().abs()\n","        upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n","        corr_features = [column for column in upper.columns if any(upper[column] > 0.85)]\n","        self.features = [col for col in self.features if col not in corr_features]\n","        self.update_datasets()\n","        print(f\"Removed correlated features: {corr_features}\")\n","\n","    def train(self):\n","        if not self.features:\n","            print(\"Nenhuma característica selecionada para treinamento.\")\n","            return\n","        self.model = LGBMClassifier(random_state=self.random_state, **self.params)\n","        self.model.fit(self.X_train[self.features], self.y_train, categorical_feature=self.categorical_features)\n","\n","    def evaluate(self):\n","        if self.model is None:\n","            print(\"Modelo não foi treinado.\")\n","            return None, None\n","        print(\"Training Metrics:\")\n","        train_metrics = metricas_validacao(self.model, pd.concat([self.X_train[self.features], self.y_train], axis=1), self.target)\n","        print(\"Testing Metrics:\")\n","        test_metrics = metricas_validacao(self.model, pd.concat([self.X_test[self.features], self.y_test], axis=1), self.target)\n","        return train_metrics, test_metrics\n","\n","    def plot_roc_curve(self):\n","        if self.model is None:\n","            print(\"Modelo não foi treinado.\")\n","            return\n","        prob_test = self.model.predict_proba(self.X_test[self.features])[:, 1]\n","        fpr, tpr, _ = metrics.roc_curve(self.y_test, prob_test)\n","        auc = metrics.roc_auc_score(self.y_test, prob_test)\n","\n","        plt.figure(dpi=300)\n","        plt.plot(fpr, tpr, color=\"darkorange\", label=\"AUC = %0.2f\" % auc)\n","        plt.plot([0, 1], [0, 1], color=\"navy\", linestyle=\"--\")\n","        plt.xlim([0.0, 1.0])\n","        plt.ylim([0.0, 1.05])\n","        plt.xlabel(\"False Positive Rate\")\n","        plt.ylabel(\"True Positive Rate\")\n","        plt.title(\"ROC Curve\")\n","        plt.legend(loc=\"lower right\")\n","        plt.show()\n","\n","    def plot_feature_importance(self):\n","        if self.model is None:\n","            print(\"Modelo não foi treinado.\")\n","            return\n","        feature_importances = pd.DataFrame(self.model.feature_importances_, index=self.features, columns=['importance']).sort_values('importance', ascending=False)\n","        plt.figure(dpi=300)\n","        sns.barplot(x=feature_importances['importance'], y=feature_importances.index)\n","        plt.ylabel(\"Feature\")\n","        plt.title(\"Feature Importances\")\n","        plt.show()\n","\n","    def borutapy_features_select(self, max_iter=100):\n","        convert_data_types()\n","        rf = RandomForestClassifier(n_jobs=-1, random_state=self.random_state, n_estimators=5)\n","        boruta = BorutaPy(estimator=rf, n_estimators='auto', max_iter=max_iter, verbose=1, random_state=self.random_state)\n","        boruta.fit(self.X_train[self.features].values, self.y_train.values)\n","        green_area = self.X_train[self.features].columns[boruta.support_].tolist()\n","        self.features = green_area\n","        print(f\"Selected features (BorutaPy): {self.features}\")\n","        self.update_datasets()\n","        self.train()\n","\n","    def mrmr_features_select(self, k):\n","        selected_features_mrmr = mrmr.mrmr_classif(X=self.X_train[self.features], y=self.y_train, K=k)\n","        self.features = selected_features_mrmr\n","        print(f\"Selected features (MRMR): {self.features}\")\n","        self.update_datasets()\n","        self.train()\n","\n","    def forward_features_select(self, k_folds=5, max_time=3600):\n","        start_time = time.time()\n","        skf = StratifiedKFold(n_splits=k_folds, random_state=self.random_state, shuffle=True)\n","        features_temp = self.features.copy()\n","        selected_features = []\n","        model = LGBMClassifier(random_state=self.random_state)\n","        while len(features_temp) > 0:\n","            if time.time() - start_time > max_time:\n","                print(\"Reached maximum time limit for feature selection.\")\n","                break\n","\n","            best_score = 0\n","            best_feature = None\n","            for feature in features_temp:\n","                current_features = selected_features + [feature]\n","                scores = []\n","                for train_idx, val_idx in skf.split(self.X_train, self.y_train):\n","                    model.fit(self.X_train.iloc[train_idx][current_features], self.y_train.iloc[train_idx])\n","                    pred = model.predict_proba(self.X_train.iloc[val_idx][current_features])[:, 1]\n","                    scores.append(metrics.roc_auc_score(self.y_train.iloc[val_idx], pred))\n","                mean_score = np.mean(scores)\n","                if mean_score > best_score:\n","                    best_score = mean_score\n","                    best_feature = feature\n","            if best_feature is not None:\n","                selected_features.append(best_feature)\n","                features_temp.remove(best_feature)\n","                print(f\"Selected feature: {best_feature} with AUC: {best_score:.4f}\")\n","            else:\n","                break\n","        self.features = selected_features\n","        self.update_datasets()\n","        self.train()\n","\n","    def full_optuna(self, k_folds=5):\n","        \"\"\"Otimiza hiperparâmetros usando Optuna.\"\"\"\n","        def objective(trial):\n","            param_grid = {\n","                'n_estimators': trial.suggest_int('n_estimators', 10, 50),\n","                'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.2),\n","                'num_leaves': trial.suggest_int('num_leaves', 20, 80),\n","                'max_depth': trial.suggest_int('max_depth', 3, 15),\n","                'min_child_samples': trial.suggest_int('min_child_samples', 10, 50),\n","                'subsample': trial.suggest_float('subsample', 0.6, 0.9),\n","                'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 0.9),\n","                'reg_alpha': trial.suggest_float('reg_alpha', 0.01, 1.0),\n","                'reg_lambda': trial.suggest_float('reg_lambda', 0.01, 1.0)\n","            }\n","            scores = []\n","            model = LGBMClassifier(**param_grid, random_state=self.random_state)\n","            for train_idx, val_idx in StratifiedKFold(n_splits=k_folds, shuffle=True, random_state=self.random_state).split(self.X_train, self.y_train):\n","                model.fit(self.X_train.iloc[train_idx], self.y_train.iloc[train_idx])\n","                preds = model.predict_proba(self.X_train.iloc[val_idx])[:, 1]\n","                score = metrics.roc_auc_score(self.y_train.iloc[val_idx], preds)\n","                scores.append(score)\n","            return np.mean(scores)\n","\n","        study = create_study(direction='maximize')\n","        study.optimize(objective, n_trials=50)\n","        self.params = study.best_params\n","        print(f\"Best parameters (Optuna): {self.params}\")\n","        self.update_datasets()\n","        self.train()\n","\n","    def update_datasets(self):\n","        \"\"\"Atualiza os datasets de treino e teste com as features selecionadas.\"\"\"\n","        self.X_train = self.X_train[self.features]\n","        self.X_test = self.X_test[self.features]\n","\n","    def predict(self, X):\n","        \"\"\"Retorna as previsões binárias do modelo treinado.\"\"\"\n","        if self.model is None:\n","            raise ValueError(\"O modelo não foi treinado ainda.\")\n","        return self.model.predict(X[self.features])\n","\n","    def predict_proba(self, X):\n","        \"\"\"Retorna as previsões de probabilidade do modelo treinado.\"\"\"\n","        if self.model is None:\n","            raise ValueError(\"O modelo não foi treinado ainda.\")\n","        return self.model.predict_proba(X[self.features])[:, 1]\n","\n","    def save_model(self, filename, path='.'):\n","        full_path = os.path.join(path, filename)\n","        joblib.dump(self.model, full_path)\n","        print(f\"Modelo salvo como {full_path}\")\n","\n","    def save_metrics(self, filename, train_metrics, test_metrics, path='.'):\n","        full_path = os.path.join(path, filename)\n","        metrics = {\n","            'train_metrics': train_metrics,\n","            'test_metrics': test_metrics\n","        }\n","        with open(full_path, 'w') as f:\n","            json.dump(metrics, f)\n","        print(f\"Métricas salvas como {full_path}\")\n","\n","    def save_feature_importances(self, filename, path='.'):\n","        full_path = os.path.join(path, filename)\n","        feature_importances = pd.DataFrame(self.model.feature_importances_, index=self.features, columns=['importance']).sort_values('importance', ascending=False)\n","        feature_importances.to_csv(full_path)\n","        print(f\"Importância das features salva como {full_path}\")\n","\n","    def save_features(self, filename='features.txt', path='.'):\n","        full_path = os.path.join(path, filename)\n","        with open(full_path, 'w') as f:\n","            for feature in self.features:\n","                f.write(f\"{feature}\\n\")\n","        print(f\"Features salvas em {full_path}\")\n","\n","    def save_plots(self, path='.'):\n","        self.save_roc_curve(path)\n","        self.save_feature_importance_plot(path)\n","\n","    def save_roc_curve(self, path='.'):\n","        save_plot(self.plot_roc_curve, 'curva_roc', path, format='pdf')\n","\n","    def save_feature_importance_plot(self, path='.'):\n","        save_plot(self.plot_feature_importance, 'importancia_das_features', path, format='pdf')\n","\n","    def run(self):\n","        self.find_irrelevant_features()\n","        self.find_correlated_features()\n","        self.train()\n","        train_metrics, test_metrics = self.evaluate()\n","        if train_metrics is None or test_metrics is None:\n","            print(\"Não foi possível avaliar o modelo.\")\n","            return\n","        self.plot_roc_curve()\n","        self.plot_feature_importance()\n","        return\n"]}]}