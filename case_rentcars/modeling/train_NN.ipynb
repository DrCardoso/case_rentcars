{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPblsCQSRldZ+sx2QPsQXZv"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"8pmLot7zNuvZ"},"outputs":[],"source":["def save_model_info(model_NN_, base_path='model_info'):\n","    import os\n","\n","    if not os.path.exists(base_path):\n","        os.makedirs(base_path)\n","\n","    # Salvar o modelo completo\n","    model_NN_.model.save(os.path.join(base_path, 'model_complete.h5'))\n","\n","    # Salvar pesos do modelo\n","    model_NN_.model.save_weights(os.path.join(base_path, 'model_weights.h5'))\n","\n","    # Salvar arquitetura do modelo\n","    with open(os.path.join(base_path, 'model_architecture.json'), 'w') as f:\n","        f.write(model_NN_.model.to_json())\n","\n","    # Salvar o histórico de treinamento\n","    with open(os.path.join(base_path, 'training_history.pkl'), 'wb') as f:\n","        pickle.dump(model_NN_.history.history, f)\n","\n","    # Salvar o escalador\n","    joblib.dump(model_NN_.scaler, os.path.join(base_path, 'scaler.pkl'))\n","\n","    # Salvar configurações do modelo\n","    config = {\n","        'test_size': model_NN_.test_size,\n","        'random_state': model_NN_.random_state,\n","        'epochs': model_NN_.epochs,\n","        'batch_size': model_NN_.batch_size,\n","        'learning_rate': model_NN_.learning_rate,\n","        'scaling_method': model_NN_.scaling_method,\n","        'features': model_NN_.features,\n","        'target': model_NN_.target\n","    }\n","\n","    with open(os.path.join(base_path, 'model_config.json'), 'w') as f:\n","        json.dump(config, f)\n","\n","    # Avaliar e salvar resultados de avaliação\n","    train_metrics, test_metrics = model_NN_.evaluate()\n","\n","    evaluation_results = {\n","        'train_metrics': train_metrics,\n","        'test_metrics': test_metrics\n","    }\n","\n","    with open(os.path.join(base_path, 'evaluation_results.json'), 'w') as f:\n","        json.dump(evaluation_results, f)\n","\n","# EXEMPLO DE COMO USAR:\n","# Especificar o diretório onde as informações serão salvas\n","# directory_path = 'path/to/save/model_info'\n","# Salvar todas as informações importantes\n","# save_model_info(model_NN_, base_path=directory_path)\n","\n","\n","### Função para calcular a métrica pedida pela competição\n","def instacart_f1_score(data, user_id_col, true_col, pred_col):\n","    f1_scores = []\n","\n","    users = data[user_id_col].unique()\n","    for user in users:\n","        user_data = data[data[user_id_col] == user]\n","\n","        # Garantir que true_col e pred_col sejam conjuntos\n","        if isinstance(user_data[true_col].values[0], (np.integer, int)):\n","            y_true = {user_data[true_col].values[0]}\n","        else:\n","            y_true = set(user_data[true_col].values[0])\n","\n","        if isinstance(user_data[pred_col].values[0], (np.integer, int)):\n","            y_pred = {user_data[pred_col].values[0]}\n","        else:\n","            y_pred = set(user_data[pred_col].values[0])\n","\n","        if len(y_true) == 0 and len(y_pred) == 0:\n","            f1_scores.append(1.0)\n","        elif len(y_true) == 0 or len(y_pred) == 0:\n","            f1_scores.append(0.0)\n","        else:\n","            tp = len(y_true & y_pred)\n","            fp = len(y_pred - y_true)\n","            fn = len(y_true - y_pred)\n","\n","            precision = tp / (tp + fp) if tp + fp > 0 else 0\n","            recall = tp / (tp + fn) if tp + fn > 0 else 0\n","            f1 = 2 * precision * recall / (precision + recall) if precision + recall > 0 else 0\n","            f1_scores.append(f1)\n","\n","    return np.mean(f1_scores)\n","\n","# Função de avaliação\n","def metricas_validacao_NN(model, X, y, threshold=0.5):\n","    prob = model.predict(X)\n","    y_pred = (prob > threshold).astype(int)\n","\n","    auc = roc_auc_score(y, prob)\n","    logloss = log_loss(y, prob)\n","    accuracy = accuracy_score(y, y_pred)\n","    precision = precision_score(y, y_pred)\n","    recall = recall_score(y, y_pred)\n","    f1 = f1_score(y, y_pred)\n","\n","    print(f'AUC: {auc:.4f}, Log Loss: {logloss:.4f}, Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}')\n","    return auc, logloss, accuracy, precision, recall, f1\n","\n","class SimplifiedNNModel:\n","    def __init__(self, data, features, target, test_flag_label=None, test_size=0.3, random_state=42, epochs=50, batch_size=32, learning_rate=0.001, scaling_method='standard'):\n","        self.data = data\n","        self.features = features\n","        self.target = target\n","        self.test_flag_label = test_flag_label\n","        self.test_size = test_size\n","        self.random_state = random_state\n","        self.epochs = epochs\n","        self.batch_size = batch_size\n","        self.learning_rate = learning_rate\n","        self.scaling_method = scaling_method\n","        self.model = None\n","        self.history = None\n","        self.scaler = None\n","        self.preprocess()\n","\n","    def preprocess(self):\n","        if self.test_flag_label:\n","            train_data = self.data[self.data[self.test_flag_label] == 0]\n","            test_data = self.data[self.data[self.test_flag_label] == 1]\n","            self.X_train, self.y_train = train_data[self.features], train_data[self.target]\n","            self.X_test, self.y_test = test_data[self.features], test_data[self.target]\n","        else:\n","            X = self.data[self.features]\n","            y = self.data[self.target]\n","            self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(X, y, test_size=self.test_size, random_state=self.random_state, stratify=y)\n","\n","        # Escolha do método de escalonamento\n","        if self.scaling_method == 'standard':\n","            self.scaler = StandardScaler()\n","        elif self.scaling_method == 'minmax':\n","            self.scaler = MinMaxScaler()\n","        else:\n","            raise ValueError(\"Método de escalonamento inválido. Use 'standard' ou 'minmax'.\")\n","\n","        self.scaler.fit(self.X_train)\n","        self.X_train = self.scaler.transform(self.X_train)\n","        self.X_test = self.scaler.transform(self.X_test)\n","\n","    def build_model(self):\n","        model = Sequential()\n","        model.add(Dense(254, input_dim=len(self.features), activation='relu'))\n","        model.add(Dropout(0.5))\n","        model.add(Dense(128, activation='relu'))\n","        model.add(Dropout(0.5))\n","        model.add(Dense(64, activation='relu'))\n","        model.add(Dropout(0.5))\n","        model.add(Dense(32, activation='relu'))\n","        model.add(Dropout(0.5))\n","        model.add(Dense(1, activation='sigmoid'))\n","\n","        optimizer = Adam(learning_rate=self.learning_rate)\n","        model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n","        return model\n","\n","    def train(self):\n","        self.model = self.build_model()\n","        self.history = self.model.fit(self.X_train, self.y_train, epochs=self.epochs, batch_size=self.batch_size, validation_data=(self.X_test, self.y_test), verbose=1)\n","\n","    def evaluate(self):\n","        if self.model is None:\n","            print(\"Modelo não foi treinado.\")\n","            return None, None\n","        print(\"Training Metrics:\")\n","        train_metrics = metricas_validacao_NN(self.model, self.X_train, self.y_train)\n","        print(\"Testing Metrics:\")\n","        test_metrics = metricas_validacao_NN(self.model, self.X_test, self.y_test)\n","        return train_metrics, test_metrics\n","\n","    def plot_roc_curve(self):\n","        if self.model is None:\n","            print(\"Modelo não foi treinado.\")\n","            return\n","        prob_test = self.model.predict(self.X_test)\n","        fpr, tpr, _ = roc_curve(self.y_test, prob_test)\n","        auc = roc_auc_score(self.y_test, prob_test)\n","\n","        plt.figure(dpi=300)\n","        plt.plot(fpr, tpr, color=\"darkorange\", label=\"AUC = %0.2f\" % auc)\n","        plt.plot([0, 1], [0, 1], color=\"navy\", linestyle=\"--\")\n","        plt.xlim([0.0, 1.0])\n","        plt.ylim([0.0, 1.05])\n","        plt.xlabel(\"False Positive Rate\")\n","        plt.ylabel(\"True Positive Rate\")\n","        plt.title(\"ROC Curve\")\n","        plt.legend(loc=\"lower right\")\n","        plt.show()\n","\n","    def plot_loss(self):\n","        if self.model is None:\n","            print(\"Modelo não foi treinado.\")\n","            return\n","        history = self.history.history\n","        plt.figure(dpi=300)\n","        plt.plot(history['loss'], label='train_loss')\n","        plt.plot(history['val_loss'], label='val_loss')\n","        plt.xlabel('Epochs')\n","        plt.ylabel('Loss')\n","        plt.title('Loss Curve')\n","        plt.legend(loc='upper right')\n","        plt.show()\n","\n","    def predict(self, new_data, threshold=0.5):\n","        if self.model is None:\n","            raise ValueError(\"O modelo não foi treinado ainda.\")\n","        new_data_scaled = self.scaler.transform(new_data)\n","        probabilities = self.model.predict(new_data_scaled)\n","        binary_predictions = (probabilities > threshold).astype(int)\n","        return probabilities, binary_predictions\n","\n","    def run(self):\n","        self.train()\n","        train_metrics, test_metrics = self.evaluate()\n","        if train_metrics is None or test_metrics is None:\n","            print(\"Não foi possível avaliar o modelo.\")\n","            return\n","        self.plot_roc_curve()\n","        self.plot_loss()\n","        return\n","\n","# Exemplo de uso:\n","# model = SimplifiedNNModel(data=df, features=['feature1', 'feature2'], target='target', test_flag_label='is_test')\n","# model.run()\n"]}]}